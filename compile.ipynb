{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c7c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "# uv pip install torch==2.10.0 torchvision==0.25.0 triton==3.6.0 --index-url https://download.pytorch.org/whl/cu128\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "def compile_model_once(model=None, precision=\"fp16\",backend=\"inductor\",\n",
    "                       compile_mode=\"reduce-overhead\", fullgraph=False):\n",
    "\n",
    "    if precision == \"fp16\":\n",
    "        model = model.half()\n",
    "        \n",
    "    if hasattr(model, 'backbone') and hasattr(model.backbone, 'patch_embed'):\n",
    "        stem_layer = model.backbone.patch_embed.backbone.stem\n",
    "    # This tells the compiler: \"When you hit this function, stop compiling, run it normally, and resume compilation afterward.\"\n",
    "# torch._dynamo.disable(model.backbone.patch_embed.backbone.stem.forward)\n",
    "    #decorate the forward pass of the stem to be skipped by Dynamo\n",
    "        stem_layer.forward = torch._dynamo.disable(stem_layer.forward)\n",
    "        print(\"Optimization disabled for ResNet stem to prevent LoweringException.\")\n",
    "        \n",
    "\n",
    "    compiled_model = torch.compile(\n",
    "        model,\n",
    "        backend=backend, #aot_eager\n",
    "        mode=compile_mode,\n",
    "        dynamic=False\n",
    "    )\n",
    "\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a386f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_input_dtype(model, input_tensor):\n",
    "    model_dtype = next(model.parameters()).dtype\n",
    "    return input_tensor.to(dtype=model_dtype)\n",
    "\n",
    "def preprocess_frame(frame, resolution, device):\n",
    "    frame_resized = cv2.resize(frame, (resolution, resolution))\n",
    "    rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    rgb = rgb / 255.0\n",
    "\n",
    "    tensor = torch.from_numpy(rgb).permute(2,0,1).float().unsqueeze(0)\n",
    "    return tensor.to(device)\n",
    "def infer_image(compiled_model,\n",
    "                image_path,\n",
    "                transform_fn,\n",
    "                device=\"cuda\",\n",
    "                warmup_runs=5,\n",
    "                measure_runs=30,\n",
    "                output_path=\"depth_output.png\"):\n",
    "\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        raise ValueError(\"Invalid image path\")\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # input_tensor = transform_fn(img_rgb).to(device)\n",
    "    input_tensor = preprocess_frame(frame, 384, device)\n",
    "    input_tensor = align_input_dtype(compiled_model, input_tensor)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup_runs):\n",
    "        with torch.no_grad():\n",
    "            _ = compiled_model(input_tensor)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    for _ in range(measure_runs):\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            depth = compiled_model(input_tensor)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "        latencies.append((end - start) * 1000)\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    mean_latency = latencies.mean()\n",
    "    fps = 1000.0 / mean_latency\n",
    "    peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "    # Save output\n",
    "    depth_np = depth.squeeze().detach().cpu().numpy()\n",
    "    depth_norm = (depth_np - depth_np.min()) / (depth_np.max() - depth_np.min() + 1e-6)\n",
    "    depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "    depth_color = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    cv2.putText(depth_color,\n",
    "                f\"FPS: {fps:.2f}\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (255, 255, 255),\n",
    "                2)\n",
    "\n",
    "    cv2.imwrite(output_path, depth_color)\n",
    "\n",
    "    print(\"------ IMAGE INFERENCE ------\")\n",
    "    print(f\"Mean Latency: {mean_latency:.2f} ms\")\n",
    "    print(f\"P95 Latency: {np.percentile(latencies,95):.2f} ms\")\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "    print(f\"Peak Memory: {peak_mem:.2f} MB\")\n",
    "\n",
    "    return {\n",
    "        \"MeanLatency_ms\": float(mean_latency),\n",
    "        \"FPS\": float(fps),\n",
    "        \"PeakMemory_MB\": float(peak_mem)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cd7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_colormap(depth_tensor):\n",
    "    depth = depth_tensor.squeeze().detach().cpu().numpy()\n",
    "    dmin, dmax = float(depth.min()), float(depth.max())\n",
    "    depth_norm = (depth - dmin) / (dmax - dmin + 1e-6)\n",
    "    depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "    depth_color = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
    "    return depth_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3538098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_video(compiled_model,\n",
    "                video_path,\n",
    "                transform_fn,\n",
    "                device=\"cuda\",\n",
    "                warmup_frames=5,\n",
    "                measure_frames=100,\n",
    "                output_path=\"depth_video_output.mp4\"):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    orig_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(output_path, fourcc,\n",
    "                             orig_fps if orig_fps > 0 else 30,\n",
    "                             (384, 384))\n",
    "\n",
    "    frame_count = 0\n",
    "    latencies = []\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (384, 384))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0\n",
    "        frame = torch.from_numpy(frame).permute(2,0,1).float().unsqueeze(0).to(device)\n",
    "        if next(compiled_model.parameters()).dtype == torch.float16:\n",
    "                frame = frame.half()\n",
    "        if frame_count < warmup_frames:\n",
    "            with torch.no_grad():\n",
    "                _ = compiled_model(frame)\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            depth = compiled_model(frame)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "        latency_ms = (end - start) * 1000\n",
    "        latencies.append(latency_ms)\n",
    "\n",
    "        # Visualization\n",
    "        depth_np = depth.squeeze().detach().cpu().numpy()\n",
    "        depth_norm = (depth_np - depth_np.min()) / (depth_np.max() - depth_np.min() + 1e-6)\n",
    "        depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "        depth_color = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "        fps = 1000.0 / latency_ms\n",
    "\n",
    "        cv2.putText(depth_color,\n",
    "                    f\"FPS: {fps:.2f}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (255, 255, 255),\n",
    "                    2)\n",
    "\n",
    "        writer.write(depth_color)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= warmup_frames + measure_frames:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "    mean_latency = latencies.mean()\n",
    "    fps = 1000.0 / mean_latency\n",
    "    peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "    print(\"------ VIDEO INFERENCE ------\")\n",
    "    print(f\"Mean Latency: {mean_latency:.2f} ms\")\n",
    "    print(f\"P95 Latency: {np.percentile(latencies,95):.2f} ms\")\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "    print(f\"Peak Memory: {peak_mem:.2f} MB\")\n",
    "\n",
    "    return {\n",
    "        \"MeanLatency_ms\": float(mean_latency),\n",
    "        \"FPS\": float(fps),\n",
    "        \"PeakMemory_MB\": float(peak_mem)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9922e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/RUS_CIP/st189432/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/RUS_CIP/st189432/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ IMAGE INFERENCE ------\n",
      "Mean Latency: 9.31 ms\n",
      "P95 Latency: 9.65 ms\n",
      "FPS: 107.41\n",
      "Peak Memory: 269.17 MB\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\")\n",
    "model = model.to(\"cuda\").eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "compiled_model = compile_model_once(\n",
    "    model = model,\n",
    "    precision=\"fp16\",\n",
    "    backend=\"inductor\", #eager, aot-eager\n",
    "    compile_mode = \"reduce-overhead\" #max-autotune\n",
    ")\n",
    "\n",
    "results_img = infer_image(\n",
    "    compiled_model,\n",
    "    \"Images/people.jpg\",\n",
    "    midas_transforms.dpt_transform,\n",
    "    output_path=\"depth_compile_f16.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c96432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ VIDEO INFERENCE ------\n",
      "Mean Latency: 10.05 ms\n",
      "P95 Latency: 10.41 ms\n",
      "FPS: 99.48\n",
      "Peak Memory: 919.28 MB\n"
     ]
    }
   ],
   "source": [
    "# results_img = infer_video(\n",
    "#     compiled_model,\n",
    "#     \"/home/RUS_CIP/st189432/MasterThesis/ddacs/Monocular-Depth-ViT-Optimization/test.mov\",\n",
    "#     midas_transforms.dpt_transform,\n",
    "#     output_path=\"depth_compile_f16.avi\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8592a",
   "metadata": {},
   "source": [
    "## Compilation error due to custom padding logic in MiDas architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973e7d8",
   "metadata": {},
   "source": [
    "```\n",
    "InductorError: LoweringException: AssertionError: \n",
    "  target: aten.convolution.default\n",
    "  args[0]: TensorBox(StorageBox(\n",
    "    ComputedBuffer(name='buf3', layout=FixedLayout('cuda:0', torch.float32, size=[1, 3, s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5), s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5)], stride=[3*(s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5))*(s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5)), (s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5))*(s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5)), s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5), 1]), data=Pointwise(\n",
    "      'cuda',\n",
    "      torch.float32,\n",
    "      def inner_fn(index):\n",
    "          _, i1, i2, i3 = index\n",
    "          tmp0 = ops.index_expr(i2 - ps0, torch.int64)\n",
    "          tmp1 = ops.index_expr(0, torch.int64)\n",
    "          tmp2 = tmp0 >= tmp1\n",
    "          tmp3 = ops.index_expr(i2 - ps0, torch.int64)\n",
    "          tmp4 = ops.index_expr(s53, torch.int64)\n",
    "          tmp5 = tmp3 < tmp4\n",
    "          tmp6 = ops.index_expr(i3 - ps1, torch.int64)\n",
    "          tmp7 = ops.index_expr(0, torch.int64)\n",
    "          tmp8 = tmp6 >= tmp7\n",
    "          tmp9 = ops.index_expr(i3 - ps1, torch.int64)\n",
    "          tmp10 = ops.index_expr(s0, torch.int64)\n",
    "          tmp11 = tmp9 < tmp10\n",
    "          tmp12 = tmp2 & tmp5\n",
    "          tmp13 = tmp12 & tmp8\n",
    "          tmp14 = tmp13 & tmp11\n",
    "          tmp15 = ops.load(arg2_1, i1 + -3 * ps1 + 3 * i3 + 3 * s0 * (i2 - ps0))\n",
    "          tmp16 = ops.masked(tmp14, tmp15, 0.0)\n",
    "          return tmp16\n",
    "      ,\n",
    "      ranges=[1, 3, s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5), s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5)],\n",
    "      origin_node=None,\n",
    "      origins=OrderedSet([convolution, constant_pad_nd, view_5, mul...,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfc390",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fbb217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiler run complete. Printing summary...\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         0.43%     184.005us         9.56%       4.054ms       1.351ms       0.000us         0.00%      27.022ms       9.007ms             3  \n",
      "                                               aten::to         0.01%       2.946us         0.01%       2.946us       0.982us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                               TorchDynamo Cache Lookup         0.70%     295.785us         0.70%     295.785us      10.955us       0.000us         0.00%       0.000us       0.000us            27  \n",
      "                             Torch-Compiled Region: 0/3         0.08%      33.142us         9.08%       3.851ms       1.284ms       0.000us         0.00%      27.022ms       9.007ms             3  \n",
      "                             Torch-Compiled Region: 1/3         0.08%      32.594us         8.55%       3.626ms       1.209ms       0.000us         0.00%      27.022ms       9.007ms             3  \n",
      "                             Torch-Compiled Region: 2/3         0.03%      13.926us         6.99%       2.966ms     988.652us       0.000us         0.00%      18.911ms       6.304ms             3  \n",
      "                             Torch-Compiled Region: 3/3         1.07%     454.747us         6.94%       2.943ms     981.165us       0.000us         0.00%      18.911ms       6.304ms             3  \n",
      "                             Torch-Compiled Region: 4/4         0.26%     110.719us         4.68%       1.987ms     662.274us      17.998ms        49.97%      18.050ms       6.017ms             3  \n",
      "                                      Pregraph bytecode         0.41%     173.054us         0.41%     173.054us      14.421us       0.000us         0.00%       0.000us       0.000us            12  \n",
      "                 AOTDispatcher Runtime Wrapper Prologue         0.07%      30.809us         0.07%      30.809us       2.567us       0.000us         0.00%       0.000us       0.000us            12  \n",
      "## Call CompiledFxGraph f44qjcsmxtrjesnygsobp7jlvtrk...         1.00%     423.156us         4.07%       1.725ms     574.936us       0.000us         0.00%      52.383us      17.461us             3  \n",
      "                                   aten::_foreach_copy_         0.08%      32.631us         0.17%      72.006us      24.002us      52.383us         0.15%      52.383us      17.461us             3  \n",
      "                                       cudaLaunchKernel         0.09%      39.375us         0.09%      39.375us      13.125us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                                  cudaStreamIsCapturing         0.02%       7.023us         0.02%       7.023us       0.780us       0.000us         0.00%       0.000us       0.000us             9  \n",
      "                                        cudaGraphLaunch         3.79%       1.608ms         3.79%       1.608ms     178.667us       0.000us         0.00%       0.000us       0.000us             9  \n",
      "                                   cudaDriverGetVersion         0.00%       0.722us         0.00%       0.722us       0.080us       0.000us         0.00%       0.000us       0.000us             9  \n",
      "                             Torch-Compiled Region: 5/1         0.17%      70.575us         0.72%     303.913us     101.304us     861.176us         2.39%     861.176us     287.059us             3  \n",
      "## Call CompiledFxGraph fivnw4zp2wlwpr4vhuhh76z2itzx...         0.34%     142.910us         0.51%     216.718us      72.239us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                             Torch-Compiled Region: 6/1         0.16%      66.574us         1.36%     575.583us     191.861us       8.111ms        22.52%       8.111ms       2.704ms             3  \n",
      "## Call CompiledFxGraph fl7h4yny5hkzzpabrwty5sw5dz7v...         0.41%     173.335us         1.14%     485.625us     161.875us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 42.413ms\n",
      "Self CUDA time total: 36.016ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESOLUTION = 384\n",
    "WARMUP_FRAMES = 20\n",
    "MEASURE_FRAMES = 200\n",
    "dummy_input = torch.randn(1, 3, RESOLUTION, RESOLUTION).to(DEVICE)\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA, # Only include if CUDA is available\n",
    "    ],\n",
    "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    ") as prof:\n",
    "    for i in range(10):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = align_input_dtype(compiled_model, dummy_input)\n",
    "            compiled_model(dummy_input)\n",
    "        prof.step()\n",
    "print(\"Profiler run complete. Printing summary...\")\n",
    "print(\"-\" * 50)\n",
    "print(prof.key_averages().table(sort_by=\"flops\", row_limit=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe37318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f889735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27ce63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Monocular-Depth-ViT-Optimization (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
