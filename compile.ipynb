{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97c7c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "# uv pip install torch==2.10.0 torchvision==0.25.0 triton==3.6.0 --index-url https://download.pytorch.org/whl/cu128\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "def compile_model_once(model=None, precision=\"fp16\",backend=\"inductor\",\n",
    "                       compile_mode=\"reduce-overhead\", fullgraph=False):\n",
    "\n",
    "    if precision == \"fp16\":\n",
    "        model = model.half()\n",
    "        \n",
    "    if hasattr(model, 'backbone') and hasattr(model.backbone, 'patch_embed'):\n",
    "        stem_layer = model.backbone.patch_embed.backbone.stem\n",
    "    # This tells the compiler: \"When you hit this function, stop compiling, run it normally, and resume compilation afterward.\"\n",
    "# torch._dynamo.disable(model.backbone.patch_embed.backbone.stem.forward)\n",
    "    #decorate the forward pass of the stem to be skipped by Dynamo\n",
    "        stem_layer.forward = torch._dynamo.disable(stem_layer.forward)\n",
    "        print(\"Optimization disabled for ResNet stem to prevent LoweringException.\")\n",
    "        \n",
    "\n",
    "    compiled_model = torch.compile(\n",
    "        model,\n",
    "        backend=backend, #aot_eager\n",
    "        mode=compile_mode,\n",
    "        dynamic=False\n",
    "    )\n",
    "\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a386f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_input_dtype(model, input_tensor):\n",
    "    model_dtype = next(model.parameters()).dtype\n",
    "    return input_tensor.to(dtype=model_dtype)\n",
    "\n",
    "def preprocess_frame(frame, resolution, device):\n",
    "    frame_resized = cv2.resize(frame, (resolution, resolution))\n",
    "    rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    rgb = rgb / 255.0\n",
    "\n",
    "    tensor = torch.from_numpy(rgb).permute(2,0,1).float().unsqueeze(0)\n",
    "    return tensor.to(device)\n",
    "def infer_image(compiled_model,\n",
    "                image_path,\n",
    "                transform_fn,\n",
    "                device=\"cuda\",\n",
    "                warmup_runs=5,\n",
    "                measure_runs=30,\n",
    "                output_path=\"depth_output.png\"):\n",
    "\n",
    "    frame = cv2.imread(image_path)\n",
    "    if frame is None:\n",
    "        raise ValueError(\"Invalid image path\")\n",
    "\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # input_tensor = transform_fn(img_rgb).to(device)\n",
    "    input_tensor = preprocess_frame(frame, 384, device)\n",
    "    input_tensor = align_input_dtype(compiled_model, input_tensor)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup_runs):\n",
    "        with torch.no_grad():\n",
    "            _ = compiled_model(input_tensor)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    latencies = []\n",
    "\n",
    "    for _ in range(measure_runs):\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            depth = compiled_model(input_tensor)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "        latencies.append((end - start) * 1000)\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    mean_latency = latencies.mean()\n",
    "    fps = 1000.0 / mean_latency\n",
    "    peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "    # Save output\n",
    "    depth_np = depth.squeeze().detach().cpu().numpy()\n",
    "    depth_norm = (depth_np - depth_np.min()) / (depth_np.max() - depth_np.min() + 1e-6)\n",
    "    depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "    depth_color = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "    cv2.putText(depth_color,\n",
    "                f\"FPS: {fps:.2f}\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (255, 255, 255),\n",
    "                2)\n",
    "\n",
    "    cv2.imwrite(output_path, depth_color)\n",
    "\n",
    "    print(\"------ IMAGE INFERENCE ------\")\n",
    "    print(f\"Mean Latency: {mean_latency:.2f} ms\")\n",
    "    print(f\"P95 Latency: {np.percentile(latencies,95):.2f} ms\")\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "    print(f\"Peak Memory: {peak_mem:.2f} MB\")\n",
    "\n",
    "    return {\n",
    "        \"MeanLatency_ms\": float(mean_latency),\n",
    "        \"FPS\": float(fps),\n",
    "        \"PeakMemory_MB\": float(peak_mem)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67cd7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_colormap(depth_tensor):\n",
    "    depth = depth_tensor.squeeze().detach().cpu().numpy()\n",
    "    dmin, dmax = float(depth.min()), float(depth.max())\n",
    "    depth_norm = (depth - dmin) / (dmax - dmin + 1e-6)\n",
    "    depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "    depth_color = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
    "    return depth_color\n",
    "\n",
    "\n",
    "def run_inference(\n",
    "    compiled_model,\n",
    "    source,\n",
    "    transform_fn,\n",
    "    device=\"cuda\",\n",
    "    warmup_runs=5,\n",
    "    measure_runs=30,\n",
    "    save=False,\n",
    "    output_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs inference on compiled model.\n",
    "\n",
    "    Parameters:\n",
    "        compiled_model : torch.compile wrapped model\n",
    "        source         : image path or video path\n",
    "        transform_fn   : MiDaS transform function\n",
    "        warmup_runs    : warmup iterations\n",
    "        measure_runs   : measured iterations\n",
    "    \"\"\"\n",
    "\n",
    "    assert compiled_model is not None, \"Model must be pre-compiled\"\n",
    "    compiled_model.eval()\n",
    "\n",
    "    is_video = source.lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\"))\n",
    "\n",
    "    latencies = []\n",
    "    outputs = []\n",
    "\n",
    "    if is_video:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        orig_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        if save:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "            writer = cv2.VideoWriter(\n",
    "                output_path,\n",
    "                fourcc,\n",
    "                orig_fps if orig_fps > 0 else 30,\n",
    "                (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                 int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "            )\n",
    "    else:\n",
    "        frame = cv2.imread(source)\n",
    "        if frame is None:\n",
    "            raise ValueError(\"Invalid image path\")\n",
    "\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        input_tensor = transform_fn(img_rgb).to(device)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Warmup phase\n",
    "    # -----------------------------\n",
    "    if not is_video:\n",
    "        for _ in range(warmup_runs):\n",
    "            with torch.no_grad():\n",
    "                _ = compiled_model(input_tensor)\n",
    "    else:\n",
    "        count = 0\n",
    "        while count < warmup_runs:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            input_tensor = transform_fn(img_rgb).to(device)\n",
    "            if next(compiled_model.parameters()).dtype == torch.float16:\n",
    "                input_tensor = input_tensor.half()\n",
    "            with torch.no_grad():\n",
    "                _ = compiled_model(input_tensor)\n",
    "            count += 1\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Measurement phase\n",
    "    # -----------------------------\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    if not is_video:\n",
    "        for _ in range(measure_runs):\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = compiled_model(input_tensor)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "\n",
    "            latencies.append((end - start) * 1000)\n",
    "            outputs.append(output.detach().cpu())\n",
    "\n",
    "            if save:\n",
    "                depth_color = depth_to_colormap(output)\n",
    "                fps = 1000.0 / latencies[-1]\n",
    "                depth_color = overlay_fps(depth_color, fps)\n",
    "                cv2.imwrite(output_path, depth_color)\n",
    "\n",
    "    else:\n",
    "        count = 0\n",
    "        while count < measure_runs:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            input_tensor = transform_fn(img_rgb).to(device)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = compiled_model(input_tensor)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "\n",
    "            latency_ms = (end - start) * 1000\n",
    "            latencies.append(latency_ms)\n",
    "\n",
    "            if save:\n",
    "                depth_color = depth_to_colormap(output)\n",
    "                fps = 1000.0 / latency_ms\n",
    "                depth_color = overlay_fps(depth_color, fps)\n",
    "                writer.write(depth_color)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        cap.release()\n",
    "        if save:\n",
    "            writer.release()\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "\n",
    "    results = {\n",
    "        \"MeanLatency_ms\": float(latencies.mean()),\n",
    "        \"P50_ms\": float(np.percentile(latencies, 50)),\n",
    "        \"P95_ms\": float(np.percentile(latencies, 95)),\n",
    "        \"FPS\": float(1000.0 / latencies.mean()),\n",
    "        \"PeakMemory_MB\": float(torch.cuda.max_memory_allocated() / (1024**2))\n",
    "    }\n",
    "\n",
    "    return results, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3538098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_video(compiled_model,\n",
    "                video_path,\n",
    "                transform_fn,\n",
    "                device=\"cuda\",\n",
    "                warmup_frames=5,\n",
    "                measure_frames=100,\n",
    "                output_path=\"depth_video_output.mp4\"):\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    orig_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(output_path, fourcc,\n",
    "                             orig_fps if orig_fps > 0 else 30,\n",
    "                             (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "    latencies = []\n",
    "\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        input_tensor = transform_fn(img_rgb).to(device)\n",
    "        input_tensor = align_input_dtype(compiled_model, input_tensor)\n",
    "\n",
    "        if frame_count < warmup_frames:\n",
    "            with torch.no_grad():\n",
    "                _ = compiled_model(input_tensor)\n",
    "            frame_count += 1\n",
    "            continue\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            depth = compiled_model(input_tensor)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "\n",
    "        latency_ms = (end - start) * 1000\n",
    "        latencies.append(latency_ms)\n",
    "\n",
    "        # Visualization\n",
    "        depth_np = depth.squeeze().detach().cpu().numpy()\n",
    "        depth_norm = (depth_np - depth_np.min()) / (depth_np.max() - depth_np.min() + 1e-6)\n",
    "        depth_uint8 = (depth_norm * 255).astype(np.uint8)\n",
    "        depth_color = cv2.applyColorMap(depth_uint8, cv2.COLORMAP_INFERNO)\n",
    "\n",
    "        fps = 1000.0 / latency_ms\n",
    "\n",
    "        cv2.putText(depth_color,\n",
    "                    f\"FPS: {fps:.2f}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (255, 255, 255),\n",
    "                    2)\n",
    "\n",
    "        writer.write(depth_color)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count >= warmup_frames + measure_frames:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    writer.release()\n",
    "\n",
    "    latencies = np.array(latencies)\n",
    "    mean_latency = latencies.mean()\n",
    "    fps = 1000.0 / mean_latency\n",
    "    peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "    print(\"------ VIDEO INFERENCE ------\")\n",
    "    print(f\"Mean Latency: {mean_latency:.2f} ms\")\n",
    "    print(f\"P95 Latency: {np.percentile(latencies,95):.2f} ms\")\n",
    "    print(f\"FPS: {fps:.2f}\")\n",
    "    print(f\"Peak Memory: {peak_mem:.2f} MB\")\n",
    "\n",
    "    return {\n",
    "        \"MeanLatency_ms\": float(mean_latency),\n",
    "        \"FPS\": float(fps),\n",
    "        \"PeakMemory_MB\": float(peak_mem)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9922e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/RUS_CIP/st189432/.cache/torch/hub/intel-isl_MiDaS_master\n",
      "Using cache found in /home/RUS_CIP/st189432/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ IMAGE INFERENCE ------\n",
      "Mean Latency: 9.81 ms\n",
      "P95 Latency: 10.29 ms\n",
      "FPS: 101.93\n",
      "Peak Memory: 902.34 MB\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\")\n",
    "model = model.to(\"cuda\").eval()\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "compiled_model = compile_model_once(\n",
    "    model = model,\n",
    "    precision=\"fp16\",\n",
    "    backend=\"inductor\", #eager, aot-eager\n",
    "    compile_mode = \"reduce-overhead\" #max-autotune\n",
    ")\n",
    "\n",
    "results_img = infer_image(\n",
    "    compiled_model,\n",
    "    \"Images/people.jpg\",\n",
    "    midas_transforms.dpt_transform,\n",
    "    output_path=\"depth_compile_f32.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8592a",
   "metadata": {},
   "source": [
    "## Compilation error due to custom padding logic in MiDas architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973e7d8",
   "metadata": {},
   "source": [
    "```\n",
    "InductorError: LoweringException: AssertionError: \n",
    "  target: aten.convolution.default\n",
    "  args[0]: TensorBox(StorageBox(\n",
    "    ComputedBuffer(name='buf3', layout=FixedLayout('cuda:0', torch.float32, size=[1, 3, s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5), s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5)], stride=[3*(s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5))*(s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5)), (s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5))*(s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5)), s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5), 1]), data=Pointwise(\n",
    "      'cuda',\n",
    "      torch.float32,\n",
    "      def inner_fn(index):\n",
    "          _, i1, i2, i3 = index\n",
    "          tmp0 = ops.index_expr(i2 - ps0, torch.int64)\n",
    "          tmp1 = ops.index_expr(0, torch.int64)\n",
    "          tmp2 = tmp0 >= tmp1\n",
    "          tmp3 = ops.index_expr(i2 - ps0, torch.int64)\n",
    "          tmp4 = ops.index_expr(s53, torch.int64)\n",
    "          tmp5 = tmp3 < tmp4\n",
    "          tmp6 = ops.index_expr(i3 - ps1, torch.int64)\n",
    "          tmp7 = ops.index_expr(0, torch.int64)\n",
    "          tmp8 = tmp6 >= tmp7\n",
    "          tmp9 = ops.index_expr(i3 - ps1, torch.int64)\n",
    "          tmp10 = ops.index_expr(s0, torch.int64)\n",
    "          tmp11 = tmp9 < tmp10\n",
    "          tmp12 = tmp2 & tmp5\n",
    "          tmp13 = tmp12 & tmp8\n",
    "          tmp14 = tmp13 & tmp11\n",
    "          tmp15 = ops.load(arg2_1, i1 + -3 * ps1 + 3 * i3 + 3 * s0 * (i2 - ps0))\n",
    "          tmp16 = ops.masked(tmp14, tmp15, 0.0)\n",
    "          return tmp16\n",
    "      ,\n",
    "      ranges=[1, 3, s53 + Max(0, -s53 + 2*CeilToInt(IntTrueDiv(s53, 2)) + 5), s0 + Max(0, -s0 + 2*CeilToInt(IntTrueDiv(s0, 2)) + 5)],\n",
    "      origin_node=None,\n",
    "      origins=OrderedSet([convolution, constant_pad_nd, view_5, mul...,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfc390",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fbb217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0221 22:38:06.491000 2457723 torch/_dynamo/convert_frame.py:1676] [0/8] torch._dynamo hit config.recompile_limit (8)\n",
      "W0221 22:38:06.491000 2457723 torch/_dynamo/convert_frame.py:1676] [0/8]    function: 'forward' (/home/RUS_CIP/st189432/.cache/torch/hub/intel-isl_MiDaS_master/midas/dpt_depth.py:165)\n",
      "W0221 22:38:06.491000 2457723 torch/_dynamo/convert_frame.py:1676] [0/8]    last reason: 0/6: tensor 'x' stride mismatch at index 0. expected 3, actual 442368\n",
      "W0221 22:38:06.491000 2457723 torch/_dynamo/convert_frame.py:1676] [0/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W0221 22:38:06.491000 2457723 torch/_dynamo/convert_frame.py:1676] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/compile/programming_model.recompilation.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiler run complete. Printing summary...\n",
      "--------------------------------------------------\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*        28.75%      17.865ms        96.89%      60.215ms      20.072ms       0.000us         0.00%      36.124ms      12.041ms             3  \n",
      "                                               aten::to         0.00%       2.033us         0.00%       2.033us       0.678us       0.000us         0.00%       0.000us       0.000us             3  \n",
      "                               TorchDynamo Cache Lookup         0.63%     390.565us         0.63%     390.565us      26.038us       0.000us         0.00%       0.000us       0.000us            15  \n",
      "void cudnn::engines_precompiled::nhwcToNchwKernel<__...         0.00%       0.000us         0.00%       0.000us       0.000us     846.751us         2.22%     846.751us       6.998us           121  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.442ms         3.79%       1.442ms      17.801us            81  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     831.218us         2.18%     831.218us       4.198us           198  \n",
      "void cudnn::engines_precompiled::nchwToNhwcKernel<__...         0.00%       0.000us         0.00%       0.000us       0.000us       3.477ms         9.13%       3.477ms      14.860us           234  \n",
      "sm75_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwc...         0.00%       0.000us         0.00%       0.000us       0.000us       3.560ms         9.35%       3.560ms     178.012us            20  \n",
      "                                            aten::slice         0.11%      67.942us         0.15%      93.679us       1.952us       0.000us         0.00%       0.000us       0.000us            48  \n",
      "                                       aten::as_strided         0.46%     285.051us         0.46%     285.051us       0.505us       0.000us         0.00%       0.000us       0.000us           564  \n",
      "                                           aten::select         0.23%     145.684us         0.32%     196.779us       1.682us       0.000us         0.00%       0.000us       0.000us           117  \n",
      "                                          aten::reshape         0.82%     512.381us         2.32%       1.441ms       1.854us       0.000us         0.00%       0.000us       0.000us           777  \n",
      "                                             aten::view         2.66%       1.650ms         2.66%       1.650ms       0.819us       0.000us         0.00%       0.000us       0.000us          2016  \n",
      "                                          aten::permute         0.14%      89.968us         0.19%     116.781us       2.780us       0.000us         0.00%       0.000us       0.000us            42  \n",
      "                              aten::upsample_bilinear2d         0.25%     156.425us         0.49%     302.299us      16.794us       1.433ms         3.76%       1.446ms      80.327us            18  \n",
      "                                            aten::copy_         0.25%     154.091us         0.58%     359.599us      13.318us     276.796us         0.73%     276.796us      10.252us            27  \n",
      "                                        cudaMemcpyAsync         0.18%     113.373us         0.18%     113.373us      12.597us       0.000us         0.00%       0.000us       0.000us             9  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.036ms         2.72%       1.036ms       6.730us           154  \n",
      "                                              aten::cat         0.21%     129.717us         0.37%     230.075us      19.173us     120.864us         0.32%     120.864us      10.072us            12  \n",
      "void at::native::(anonymous namespace)::upsample_bil...         0.00%       0.000us         0.00%       0.000us       0.000us       1.709ms         4.49%       1.709ms     100.502us            17  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 62.148ms\n",
      "Self CUDA time total: 38.082ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RESOLUTION = 384\n",
    "WARMUP_FRAMES = 20\n",
    "MEASURE_FRAMES = 200\n",
    "dummy_input = torch.randn(1, 3, RESOLUTION, RESOLUTION).to(DEVICE)\n",
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "        torch.profiler.ProfilerActivity.CUDA, # Only include if CUDA is available\n",
    "    ],\n",
    "    schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    ") as prof:\n",
    "    for i in range(10):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = align_input_dtype(compiled_model, dummy_input)\n",
    "            compiled_model(dummy_input)\n",
    "        prof.step()\n",
    "print(\"Profiler run complete. Printing summary...\")\n",
    "print(\"-\" * 50)\n",
    "print(prof.key_averages().table(sort_by=\"flops\", row_limit=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe37318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f889735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27ce63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Monocular-Depth-ViT-Optimization (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
